# Project building a LLM From Scratch

In this project (inpired from https://github.com/rasbt/LLMs-from-scratch), I learn to build and use :
- An Byte Pair Encoding (BPE) tokenizer
- An embedding encoder
- the transformer architechture
- the attention mechanism
- the finetuning of a llm for classification and instruction-following
- the Low rank Adaptation (LORA) finetuning method.


Before running the codes:

```python
python -m venv venv
source venv/bin/activate  # (or venv\Scripts\activate for Windows CMD or .\venv\Scripts\Activate.ps1 for Windows Powershell)
pip install -r requirements.txt
```