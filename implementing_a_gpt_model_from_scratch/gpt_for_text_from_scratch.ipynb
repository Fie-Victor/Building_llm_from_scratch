{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a GPT model from Scratch To Generate Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implement a GPT-like LLM model from scratch to generate Text. let's Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration for GPT2 we will be using\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12, # numbers of head in multiattention head\n",
    "    \"n_layers\":12, #number of transformer bloclks\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False, #\"first we don't add bias to linear layers for keys, value and queries parameters\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create a GBT backbone call DummyGPTModel first before adding more sophistocation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"]) #token emmbedding layer\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"]) #position embedding layer\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"]) #dropout layer\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range (cfg[\"n_layers\"])])   #A\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])                      #B\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx) #token embeddings\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "\n",
    "        x = tok_embeds + pos_embeds #add token and position embeddings\n",
    "        x = self.drop_emb(x) #apply dropout\n",
    "        x = self.trf_blocks(x) #pass through transformer blocks\n",
    "        x = self.final_norm(x) #apply final layer normalization\n",
    "        logits = self.out_head(x) #output layer to get logits for each token in vocabulary\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class DummyTransformerBlock(nn.Module):                                             #C\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):                                                              #D\n",
    "        return x\n",
    "    \n",
    "class DummyLayerNorm(nn.Module):                                              #E                        \n",
    "    def __init__(self, normalized_shape, eps=1e-5):                          #F                     \n",
    "        super().__init__()\n",
    "\n",
    "    def forward (self, x):\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A Use a placeholder for TransformerBlock\n",
    "#B Use a placeholder for LayerNorm\n",
    "#C A simple placeholder class that will be replaced by a real TransformerBlock later\n",
    "#D This block does nothing and just returns its input.\n",
    "#E A simple placeholder class that will be replaced by a real NormBlock later\n",
    "#F The parameters here are just to mimic the LayerNorm interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "#we will use a batch of two input to try our DummyGPTModel\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output logits shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#\"using it with our DummyGPTModel\"\n",
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output logits shape:\", logits.shape) #should be (2, seq_len, vocab_size)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's implement layer normalisation to improve stability and efficiency of neural networks (avoid vanishing/exploding gradients)   \n",
    "# the goal is to adjust an NN output so that it has a mean of 0 and a standard deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#exemple\n",
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2,5)\n",
    "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU()) # relut thresholds negative values to zero (it's a activation function)\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "variance: tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#let's examine the mean and standard deviation of the output\n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"variance:\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Output: tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "After LayerNorm - Mean: tensor([[9.9341e-09],\n",
      "        [1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "After LayerNorm - Variance: tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#let's apply layer normalization\n",
    "# it consist of subtracting the mean and dividing by the standard deviation\n",
    "\n",
    "out_norm = (out-mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized Output:\", out_norm)\n",
    "print(\"After LayerNorm - Mean:\", mean)\n",
    "print(\"After LayerNorm - Variance:\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# we can turn off scientific notation for clarity\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create the class\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim)) #trainable parameter to learn correctly scaling\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim)) #trainable parameter to learn correctly scaling\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True)\n",
    "        x_norm = (x-mean) / torch.sqrt(var + self.eps) #to prevent division by 0\n",
    "        return self.scale * x_norm + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: We use biased variance (dividing by n ,number of input in the variance formula, instead of n-1)\n",
    "but this is not important here because as in our case, n is large n~n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[0.8000],\n",
      "        [0.8000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#trying the layerNorm Module\n",
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, keepdim=True, unbiased=False) #unbiased=False to get the exact variance (divided by n)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we implement GELU (Gaussian Error Linear Unit) activation fonction very popular in transformer models\n",
    "#GELU(x) = x * P(X <= x) where X ~ N(0,1) GELU(x) ~ x * 0.5 * (1 + tanh(sqrt(2/pi) * (x + 0.044715 * x^3)))\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5*x*(1+torch.tanh(torch.sqrt(torch.tensor(2.0/torch.pi))* (x+0.044715* torch.pow(x,3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\"lts's plot the functions side by side to compare them\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3,3,100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8,3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"RELU\"])):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.plot(x,y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use the GELU Module to implement the FeedForward module we will use later for transformer block\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]), #increase dimension by 4 times\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"]) #project back to original dimension\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "#test with a token embedding size of 768 and feed it a batch input with 2 samples and 3 tokens each\n",
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2,3,768)\n",
    "out = ffn(x)\n",
    "print(out.shape) #should be (2,3,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's discuss the concep of shurcut connections also called residual connections or skip connections (it helps avoid vanishing gradients)\n",
    "#it consist of adding the input of a layer to its output before passing it to the next layer\" (so gradient i slarger and allow more learning)\n",
    "\n",
    "# a neural network to illustrate shortcut connections\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shorcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shorcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            #implement5 layers\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()), #layer 1\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()), #layer 2\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()), #layer 3\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()), #layer 4\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5])) #layer 5 (no activation function here)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            #compute the layer output\n",
    "            layer_output = layer(x)\n",
    "            #check if shorcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else: x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing first without shortcut connections\n",
    "layer_sizes = [3,3,3,3,3,1]\n",
    "sample_input = torch.tensor([[1.,0.,-1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shorcut = ExampleDeepNeuralNetwork(layer_sizes, use_shorcut=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to computes gradient\n",
    "def print_gradients(model, x):\n",
    "    #forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    #calculate loss based on how close the target and the output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    #backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weigths\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.0006289089797064662\n",
      "layers.1.0.weight has gradient mean of 0.00037444636109285057\n",
      "layers.2.0.weight has gradient mean of 0.0022296393290162086\n",
      "layers.3.0.weight has gradient mean of 0.004360969644039869\n",
      "layers.4.0.weight has gradient mean of 0.01574220508337021\n"
     ]
    }
   ],
   "source": [
    "#let's apply the function to our model without shortcut connections\n",
    "print_gradients(model_without_shorcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see based on the output of the print_gradients function, the gradients become\n",
    "smaller as we progress from the last layer (layers.4) to the first layer (layers.0), which\n",
    "is a phenomenon called the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.25278669595718384\n",
      "layers.1.0.weight has gradient mean of 0.2359604835510254\n",
      "layers.2.0.weight has gradient mean of 0.3751014769077301\n",
      "layers.3.0.weight has gradient mean of 0.3039548695087433\n",
      "layers.4.0.weight has gradient mean of 1.5117788314819336\n"
     ]
    }
   ],
   "source": [
    "# a model with shortcut connections\n",
    "torch.manual_seed(123)\n",
    "model_without_shorcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shorcut=True\n",
    ")\n",
    "print_gradients(model_without_shorcut, sample_input)\n",
    "#we can see that the gradients are larger and stabilise when using shortcut connections, which can help with learning in deep networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting attention and linear layers in a transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the transformer block\n",
    "import sys\n",
    "sys.path.append(\"..\") #to import from the parent directory\n",
    "from utils import MultiHeadAttention\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads = cfg[\"n_heads\"],\n",
    "            dropout = cfg[\"drop_rate\"],\n",
    "            qkv_bias = cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "                                                                                #A\n",
    "        shortcut =x\n",
    "        x = self.norm1(x)\n",
    "        x= self.att(x)\n",
    "        x= self.drop_shortcut(x)\n",
    "        x = x + shortcut #add the original input (shortcut connection)\n",
    "\n",
    "        shortcut = x\n",
    "        x  = self.norm2(x)                                                      #B\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut                                                         #C                                             \n",
    "        return x\n",
    "\n",
    "#A Shortcut connection for attention block\n",
    "#B Shortcut connection for feed forward block\n",
    "#C Add the original input back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "torch.manual_seed(123)\n",
    "x = torch.rand(2,4,768)                                     #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape) #should be (2,4,768)\n",
    "\n",
    "#A Create sample input of shape [batch_size, num_tokens, emb_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coding the GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The GPT Model architecture implementation\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device)) #A\n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "#A The device setting will allow us to train the model on a CPU or GPU, depending on which device the input data sits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "Output logits shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.6553,  0.4158,  0.3105,  ..., -0.3362, -0.7134, -0.4805],\n",
      "         [ 0.8252, -0.8948, -0.6052,  ..., -0.6546, -0.7374, -0.3287],\n",
      "         [ 0.2420,  0.0976, -0.6097,  ..., -0.1342, -0.9561, -0.6095],\n",
      "         [-0.9763,  0.5278, -0.4405,  ...,  0.8214,  0.0259, -0.5252]],\n",
      "\n",
      "        [[-0.5229,  0.5286, -0.0876,  ..., -0.7068, -0.6913, -0.0683],\n",
      "         [ 0.1366, -0.0485,  0.2685,  ...,  0.2380, -0.6056,  0.4005],\n",
      "         [ 0.6425,  0.7836, -0.2196,  ..., -0.0201,  0.0758, -0.1705],\n",
      "         [-0.4148, -0.0514,  0.2661,  ...,  0.8324, -0.6698,  0.1016]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch\", batch)\n",
    "print(\"Output logits shape:\", out.shape) #should be (2, seq_len, vocab_size)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this 163M is different from 124M we are speaking about till reading the course book\n",
    "It's due to a concept called weight tying. the original GPT-2 architechture is reusing the weights from the token embedding layer in its output layer.\n",
    "\n",
    "to undersand let's go throught some exmaple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weigth tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "#let's remove the count of output layer parameters\n",
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weigth tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Weight tying is a technique where the weights of the input embedding layer and the output layer are shared to reduce the number of parameters in the model.\n",
    "in GPT2 the token embedding layer and the output layer share the same weights\n",
    "but in modern  implementation of LLMs weight tying is not always used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in FeedForward module: 4,722,432\n",
      "Number of parameters in Attention module: 2,360,064\n"
     ]
    }
   ],
   "source": [
    "#EXERCISE 4.1 NUMBER OF PARAMETERS IN FEED FORWARD AND ATTENTION MODULES\n",
    "\n",
    "ff_num_params = sum(p.numel() for p in FeedForward(GPT_CONFIG_124M).parameters())\n",
    "print(f\"Number of parameters in FeedForward module: {ff_num_params:,}\")\n",
    "attention_num_params = sum(p.numel() for p in model.trf_blocks[0].att.parameters())\n",
    "print(f\"Number of parameters in Attention module: {attention_num_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the memory requirements of our 163M parameters GPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model : 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4   #A\n",
    "total_size_mb = total_size_bytes / (1024**2)    #B\n",
    "print(f\"Total size of the model : {total_size_mb:.2f} MB\")\n",
    "#A Calculate the total size in bytes (assuming float32, 4 bytes per parameter)\n",
    "#B Convert to megabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the output fom GPT in text\n",
    "#A function for the GPT model to generate text\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size): #A\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]                           #B\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        logits = logits[:, -1, :]                                  #C\n",
    "        probas = torch.softmax(logits, dim=-1)                       #D\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  #E\n",
    "        idx = torch.cat((idx, idx_next), dim=1)                   #F\n",
    "\n",
    "    return idx\n",
    "\n",
    "#A idx is a (batch, n_tokens) array of indices in the current context\n",
    "#B Crop current context if it exceeds the supported context size E.g., if LLM supports only 5 tokens, and the\n",
    "#context size is 10 then only the last 5 tokens are used as context\n",
    "#C Focus only on the last time step, so that (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
    "#D probas has shape (batch, vocab_size)\n",
    "#E idx_next has shape (batch, 1)\n",
    "#F Append sampled index to the running sequence, where idx has shape (batch, n_tokens+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #add batch dimension\n",
    "print(\"encoded_tensor shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we put the model into .eval() mode, which disables random components like\n",
    "dropout, which are only used during training, and use the generate_text_simple function\n",
    "on the encoded input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output indices: tensor([[15496,    11,   314,   716, 37532, 49980,  1114, 46546, 23696, 49073]])\n",
      "output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() #set model to evaluation mode (disable dropout)\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx = encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output indices:\", out)\n",
    "print(\"output length:\", len(out[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Ae thefts For Droid analyticsAbyss\n"
     ]
    }
   ],
   "source": [
    "#convert output indices to text\n",
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
