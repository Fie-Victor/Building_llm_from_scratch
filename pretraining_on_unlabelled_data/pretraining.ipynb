{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, We will pretrained a GPT model on unlabel Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fIRST WE INSTANTIATE A gpt MODEL USING CLASS FROM PREVIOUS CHAPTER\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import GPTModel\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,   #A\n",
    "    \"emb_dim\": 768,       \n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,           #B\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "#A We shorten the context length from 1024 to 256 tokens to be abble to train on our computer faster\n",
    "#B It's possible and common to set dropout to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you 960esame WindsorFE Keith awaitedSer seriously Estimated stren\n"
     ]
    }
   ],
   "source": [
    "#utils for token -<> text conversion\n",
    "import tiktoken\n",
    "from utils import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) #add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) #remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the text generation loss\n",
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "[40, 1107, 588]]) # \"I really like\"]\n",
    "#Matching these inputs, the `targets` contain the token IDs we aim for the model to produce:\n",
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "[107, 588, 11311]]) # \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): #A\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape)\n",
    "\n",
    "#A Disable gradient tracking since we are not training, yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[13207],\n",
      "         [  552],\n",
      "         [42826]],\n",
      "\n",
      "        [[18236],\n",
      "         [ 1775],\n",
      "         [ 7055]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: hole compNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "# When we decode these tokens, we find that these output tokens are quite different from\n",
    "# the target tokens we want the model to generate:\n",
    "# Targets batch 1: effort moves you\n",
    "# Outputs batch 1: hole compNetflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([5.0559e-05, 2.4350e-05, 8.5685e-06])\n",
      "Text 2: tensor([2.1986e-05, 3.3314e-05, 5.4969e-06])\n"
     ]
    }
   ],
   "source": [
    "#text evaluation function\n",
    "# For each of the two input texts, we can print the initial softmax probability scores\n",
    "# corresponding to the target tokens via the following code:\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probabilities: tensor([ -9.8924, -10.6230, -11.6674, -10.7251, -10.3095, -12.1113])\n"
     ]
    }
   ],
   "source": [
    "#applying logarith to the probas\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\"log probabilities:\", log_probas)\n",
    "#Working with logarithms of probability scores is more manageable in mathematical\n",
    "# optimization than handling the scores directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_log-probas: tensor(-10.8881)\n"
     ]
    }
   ],
   "source": [
    "#we combine to the average\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(\"avg_log-probas:\", avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_avg_log-probas: tensor(10.8881)\n"
     ]
    }
   ],
   "source": [
    "# in deep learning, the common practice isn't to push the average log probability\n",
    "# up to 0 but rather to bring the negative average log probability down to 0. The negative\n",
    "# average log probability is simply the average log probability multiplied by -1\n",
    "neg_avg_log_probas = -avg_log_probas \n",
    "print(\"neg_avg_log-probas:\", neg_avg_log_probas) #cross entropy loss (the loss turning from negative to positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# let's briefly recall the shape of the logits and\n",
    "# target tensors\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits flat shape: torch.Size([6, 50257])\n",
      "Targets flat shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# For the cross entropy_loss function in PyTorch, we want to flatten these tensors by\n",
    "# combining them over the batch dimension\n",
    "\n",
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Logits flat shape:\", logits_flat.shape)\n",
    "print(\"Targets flat shape:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy loss: tensor(10.8881)\n"
     ]
    }
   ],
   "source": [
    "# \" the loss\"\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\"Cross entropy loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "#load the training text\n",
    "file_path = '../data_loading_and_tokenization/the-verdict.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "#check the number of characters and tokens in the dataset\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we divide the dataset into a training and a validation set and use the data loaders\n",
    "# from chapter 2 to prepare the batches for LLM trainin\n",
    "\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the train_data and val_data subsets, we can now create the respective data loader\n",
    "reusing the create_dataloader_v1 code from chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, utils\n",
    "importlib.reload(utils) #pour que les modifications dans utils soient prises en compte\n",
    "\n",
    "from utils import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DataLoader', 'Dataset', 'FeedForward', 'GELU', 'GPTDatasetV1', 'GPTModel', 'GPT_CONFIG_124M', 'LayerNorm', 'MultiHeadAttention', 'TransformerBlock', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'calc_loss_batch', 'calc_loss_loader', 'create_dataloader_v1', 'evaluate_model', 'generate', 'generate_and_print_sample', 'generate_text_simple', 'nn', 'text_to_token_ids', 'tiktoken', 'token_ids_to_text', 'torch', 'train_model_simple']\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "print(dir(utils))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "#testing the dataloader\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we implement a utility function to calculate the cross entropy loss of a given batch\n",
    "# returned via the training and validation loader:\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device) #A\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "    logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "#A the transfer to a given device allows us to transfer the data to a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this calc_loss_batch utility function, which computes the loss for a single\n",
    "batch, to implement the following calc_loss_loader function that computes the loss over\n",
    "all the batches sampled by a given data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute the training and validation loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)                                  #A\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))                #B\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()                                    #C\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return total_loss / num_batches                                       #D\n",
    "\n",
    "\n",
    "\n",
    "#A Iterative over all batches if no fixed num_batches is specified\n",
    "#B Reduce the number of batches to match the total number of batches in the data loader if num_batches\n",
    "#exceeds the number of batches in the data loader\n",
    "#C Sum loss for each batch\n",
    "#D Average the loss over all batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see this calc_loss_batch function in action, applying it to the training and\n",
    "validation set loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.997285101148817\n",
      "Validation loss: 10.988701820373535\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #A\n",
    "model.to(device)\n",
    "with torch.no_grad(): #B\n",
    "    train_loss = calc_loss_loader(train_loader, model, device) #C\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "\n",
    "#A If you have a machine with a CUDA-supported GPU, the LLM will train on the GPU without making any\n",
    "#changes to the code\n",
    "#B Disable gradient tracking for efficiency because we are not training, yet\n",
    "#C Via the `device` setting, we ensure that the data is loaded onto the same device as the LLM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the evaluate_model function gives us a numeric estimate of the model's training\n",
    "progress, this generate_and_print_sample text function provides a concrete text example\n",
    "generated by the model to judge its capabilities during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() #A\n",
    "    with torch.no_grad(): #B\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "#A Dropout is disabled during evaluation for stable, reproducible results\n",
    "#B Disable gradient tracking, which is not required during evaluation, to reduce the computational overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "        model=model, idx=encoded,\n",
    "        max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \")) # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple training function\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []  #A\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):                       #B\n",
    "        model.train()  #training mode\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()                        #C\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()                              #D\n",
    "            optimizer.step()                             #E\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step +=1\n",
    "\n",
    "\n",
    "            if global_step %eval_freq  ==0 :             #F\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}):\" \n",
    "                      f\" Train loss {train_loss:.4f}, Val loss {val_loss:.4f}\")\n",
    "                \n",
    "        generate_and_print_sample(model, tokenizer,device, start_context) #G\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "#A Initialize lists to track losses and tokens seen\n",
    "#B Start the main training loop\n",
    "#C Reset loss gradients from previous batch iteration\n",
    "#D Calculate loss gradients\n",
    "#E Update model weights using loss gradients\n",
    "#F Optional evaluation step\n",
    "#G Print a sample text after each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADAMW\n",
    "Adam optimizers are a popular choice for training deep neural networks. However, in\n",
    "our training loop, we opt for the AdamW optimizer. AdamW is a variant of Adam that\n",
    "improves the weight decay approach, which aims to minimize model complexity and\n",
    "prevent overfitting by penalizing larger weights. This adjustment allows AdamW to\n",
    "achieve more effective regularization and better generalization and is thus frequently\n",
    "used in the training of LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ensimag/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.9008, Val loss 9.9908\n",
      "Ep 1 (Step 000005): Train loss 8.1473, Val loss 8.3652\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.7714, Val loss 7.0549\n",
      "Ep 2 (Step 000015): Train loss 6.4928, Val loss 6.5674\n",
      "Every effort moves you, and,, and,,,,,,, and, and,,,, the,,,,,,,,, the,, the, and,, the,,, the, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.7501, Val loss 6.4851\n",
      "Ep 3 (Step 000025): Train loss 4.4076, Val loss 6.5411\n",
      "Every effort moves you, and I had\"                                             \n",
      "Ep 4 (Step 000030): Train loss 5.4800, Val loss 6.4137\n",
      "Ep 4 (Step 000035): Train loss 4.0277, Val loss 6.2569\n",
      "Every effort moves you--I was his the picture and I was the his I was his I was his I was the picture--and it was the picture to the picture.                   \n",
      "Ep 5 (Step 000040): Train loss 3.7084, Val loss 6.2470\n",
      "Every effort moves you know the fact, and I felt--I to the fact the picture.             \"I he was his pictures--I him--as I felt a little a little the picture to see the\n",
      "Ep 6 (Step 000045): Train loss 3.7700, Val loss 6.1353\n",
      "Ep 6 (Step 000050): Train loss 2.4511, Val loss 6.1325\n",
      "Every effort moves you know the first, and pushed one of the to the fact by his painting.            \"Oh, and I had always, and he was his own a, and down, and he was his\n",
      "Ep 7 (Step 000055): Train loss 2.3096, Val loss 6.1960\n",
      "Ep 7 (Step 000060): Train loss 2.7220, Val loss 6.2303\n",
      "Every effort moves you know,\" was not that my hostess was \"I told Mrs. \"--and by the last of the fact, and. \"I he had the head to the donkey. \"Oh, and_--because he had always his\n",
      "Ep 8 (Step 000065): Train loss 1.6831, Val loss 6.1933\n",
      "Ep 8 (Step 000070): Train loss 1.4063, Val loss 6.1900\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. \"Oh, and my work, and I didn't--and by a smile behind his close grayish beard--as if he had the donkey. \"--and by holding\n",
      "Ep 9 (Step 000075): Train loss 1.1314, Val loss 6.2853\n",
      "Ep 9 (Step 000080): Train loss 0.7112, Val loss 6.3054\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with his last word.    \"I looked at the cigars you like.\"  He placed them at my elbow and as I turned, and down the room, I had\n",
      "Ep 10 (Step 000085): Train loss 0.5474, Val loss 6.3539\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "#lets train using AdamW optimiser and with 10 epochs\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1) #A\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5 ,\n",
    "    eval_iter=1, \n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "#A The .parameters() method returns all trainable weight parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's plot training loss and validation losses side by side\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny()                           #A\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  #B\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "\n",
    "#A Create a second x-axis that shares the same y-axis\n",
    "#B Invisible plot for aligning ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that after epoch2 the model is overfitting. that's not  supprising as we have a small dataset and we use many epochs.\n",
    "In practice for big llm, there is more data and only one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoding strategies to control randomless\n",
    "#we will cover two techniques, temperature scaling, and top-k sampling,to improve our generated_text_simple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\") #we don't need GPU here for our small examples\n",
    "model.eval() #we are no more training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plug the GPTModel instance (model) into the generate_text_simple function,\n",
    "which uses the LLM to generate one token at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "        max_new_tokens=25,\n",
    "        context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "    )\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example to start with\n",
    "vocab = {\n",
    "\"closer\": 0,\n",
    "\"every\": 1,\n",
    "\"effort\": 2,\n",
    "\"forward\": 3,\n",
    "\"inches\": 4,\n",
    "\"moves\": 5,\n",
    "\"pizza\": 6,\n",
    "\"toward\": 7,\n",
    "\"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "# let's assume the LLM is given the start context \"every effort moves you\" and\n",
    "# generates the following next-token logits\n",
    "next_token_logits = torch.tensor(\n",
    "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "#then we have:\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "#now instead of using armax, we are going to use multinomial function\n",
    "\n",
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multinomial\n",
    "function samples the next token proportional to its probability score. In other words,\n",
    "\"forward\" is still the most likely token and will be selected by multinomial most of the\n",
    "time but not all the time. To illustrate this, let's implement a function that repeats this\n",
    "sampling 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, the model can produces other word than just forward for the same logits. we can further control the distribution and selection process using temperature scaling -- a fancy description for dividing the logits by a number greater than 0:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim =0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperatures greater than 1 result in more uniformly distributed token probabilities,\n",
    "and Temperatures smaller than 1 will result in more confident (sharper or more peaky)\n",
    "distributions. Let's illustrate this by plotting the original probabilities alongside\n",
    "probabilities scaled with different temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5] #A\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x+i*bar_width, scaled_probas[i], bar_width, label=f'Temperature ={T}')\n",
    "ax.set_ylabel('Probabilities')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#A Original, lower, and higher confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see in Figure 5.14, applying very small temperatures, such as 0.1, will\n",
    "result in sharper distributions such that the behavior of the multinomial function selects\n",
    "the most likely token (here: \"forward\") almost 100% of the time, approaching the\n",
    "behavior of the argmax function. Vice versa, a temperature of 5 results in a more uniform\n",
    "distribution where other tokens are selected more often. This can add more variety to the\n",
    "generated texts but also more often results in nonsensical text. For example, using the\n",
    "temperature of 5 results in texts such as \"every effort moves you pizza\" about 4% of\n",
    "the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================T=1=========\n",
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n",
      "========================T=0.1=========\n",
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n",
      "========================T=5=========\n",
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5] #A\n",
    "for temperature in temperatures:\n",
    "    print(f\"========================T={temperature}=========\")\n",
    "    scaled_probas = softmax_with_temperature(next_token_logits, temperature)\n",
    "    print_sampled_tokens(scaled_probas)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-k sampling\n",
    "\n",
    "IN top-k sampling, we can restrict the sampled tokens to the top-k most likely tokens\n",
    "and exclude all other tokens from the selection process by masking their probability scores,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex: \n",
    "\n",
    "Using top-k sampling with k=3, we focus on the 3 tokens associated with the highest logits and\n",
    "mask out all other tokens with negative infinity (-inf) before applying the softmax function. This results in a\n",
    "probability distribution with a probability value 0 assigned to all non-top-k tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "#implementation\n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequently, we apply PyTorch's where function to set the logit values of tokens that are\n",
    "below the lowest logit value within our top-3 selection to negative infinity (-inf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1], #A\n",
    "    input=torch.tensor(float('-inf')),            #B\n",
    "    other = next_token_logits                      #C\n",
    ")\n",
    "print(new_logits)\n",
    "#A Identifies logits less than the minimum in the top 3\n",
    "#B Assigns -inf to these lower logits\n",
    "#C Retains the original logits for all other tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "#Lastly, let's apply the softmax function to turn these into next-token probabilities:\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we modify the text generation function to choose the next token among these 3  non-zero probability scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A modified text generation function with more diversity\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature =1.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):                         #A\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # just the probas for last token\n",
    "        if top_k is not None:                               #B\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "            logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0.0:                                  #C\n",
    "            logits = logits / temperature     \n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:                                                  #D\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "    \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "#A For-loop is the same as before: Get logits, and only focus on last time step\n",
    "#B In this new section, we filter logits with top_k sampling\n",
    "#C This is the new section where we apply temperature scaling\n",
    "#D Carry out greedy next-token selection as before when temperature scaling is disabled\n",
    "#E Stop generating early if end-of-sequence token is encountered and eos_id is specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets's try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Hello I am  thought Jack Gisburn rather a cheap genius--I told Mrs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Hello I am \", tokenizer).to(device),\n",
    "    max_new_tokens=15,\n",
    "    context_size= GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Saving model weights in pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using torch\n",
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, after saving the model weights via the state_dict, we can load the model\n",
    "weights into a new GPTModel model instance as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval() # evaluation mode (disable dropout layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plan to continue pretrainning a model, saving optimizer is alse recomended\n",
    "Adaptive optimizers such as AdamW store additional parameters for each model weight.\n",
    "AdamW uses historical data to adjust learning rates for each model parameter dynamically.\n",
    "Without it, the optimizer resets, and the model may learn suboptimally or even fail to\n",
    "converge properly, which means that it will lose the ability to generate coherent text. Using\n",
    "torch.save, we can save both the model and optimizer state_dict contents as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\":model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimiser.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can restore the model and optimizer states as follows by first loading the saved\n",
    "data via torch.load and then using the load_state_dict method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimiser.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are going to load weight of openai gpt2 and load it in our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the dowload_and_load_gt2 function provide in course materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-22 12:44:43.975099: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-22 12:44:44.352321: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-22 12:44:44.352351: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-22 12:44:44.353053: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-22 12:44:44.458204: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-22 12:44:45.666319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'gpt_download' from '/home/ensimag/Desktop/PROJETS_IA/Building_llm_from_scratch/pretraining_on_unlabelled_data/../gpt_download.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, gpt_download\n",
    "importlib.reload(gpt_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 77.0/77.0 [00:00<00:00, 91.1kiB/s]\n",
      "encoder.json: 100%|██████████████████████████████████████████████████████████████████████████████████████| 1.04M/1.04M [00:10<00:00, 101kiB/s]\n",
      "hparams.json: 100%|███████████████████████████████████████████████████████████████████████████████████████| 90.0/90.0 [00:00<00:00, 76.5kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|███████████████████████████████████████████████████████████████████| 498M/498M [1:27:34<00:00, 94.7kiB/s]\n",
      "model.ckpt.index: 100%|█████████████████████████████████████████████████████████████████████████████████| 5.21k/5.21k [00:00<00:00, 4.03MiB/s]\n",
      "model.ckpt.meta: 100%|█████████████████████████████████████████████████████████████████████████████████████| 471k/471k [00:01<00:00, 334kiB/s]\n",
      "vocab.bpe: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 456k/456k [00:01<00:00, 265kiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the GPT-2 model weights into Python, we still need to transfer them from\n",
    "the settings and params dictionaries into our GPTModel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create a dictionary that lists the differences between the different GPT model\n",
    "# sizes:\n",
    "model_configs = {\n",
    "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "#Suppose we are interested in loading the smallest model, \"gpt2-small (124M)\". We can use\n",
    "#the corresponding settings from the model_configs table able to update our full-length\n",
    "#GPT_CONFIG_124M we defined and used earlier throughout the chapter as follows:\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "\n",
    "\n",
    "#we update from 256 to 1024 because the original openai as been trained with 1024\n",
    "NEW_CONFIG.update({\"context_length\": 1024})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, OpenAI used bias vectors in the multi-head attention module's linear layers to\n",
    "implement the query, key, and value matrix computations. Bias vectors are not commonly\n",
    "used in LLMs anymore as they don't improve the modeling performance and are thus\n",
    "unnecessary. However, since we are working with pretrained weights, we need to match the\n",
    "settings for consistency and enable these bias vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "#We can now use the updated NEW_CONFIG dictionary to initialize a new GPTModel instance:\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the GPTModel instance is initialized with random weights for pretraining. The last\n",
    "step to using OpenAI's model weights is to override these random weights with the weights\n",
    "we loaded into the params dictionary.\n",
    "For this, we will first define a small assign utility function that checks whether two\n",
    "tensors or arrays (left and right) have the same dimensions or shape and returns the\n",
    "right tensor as trainable PyTorch parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a load_weights_into_gpt function that loads the weights from the params\n",
    "dictionary into a GPTModel instance gpt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING oPENaI WEIGHTS iNTO OUR gpt MODEL CODE\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt,params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])  #A\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params['blocks'])):                       #B\n",
    "        q_w, k_w, v_w = np.split(                                #C\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        \n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "        \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"]) #D\n",
    "\n",
    "#A Setting the model's positional and token embedding weights to those specified in params.\n",
    "#B Iterate over each transformer block in the model.\n",
    "#C The np.split function is used to divide the attention and bias weights into three equal parts for the query,\n",
    "#key, and value components.\n",
    "#D The original GPT-2 model by OpenAI reused the token embedding weights in the output layer to reduce the\n",
    "#total number of parameters, which is a concept known as weight tying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try the load_weights_into_gpt out in practice and load the OpenAI model\n",
    "weights into our GPTModel instance gpt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt,params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is loaded correctly, we can now use it to generate new text using our previous\n",
    "generate function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Hello I am an actor, in all matters between myself and you...\n",
      "\"I know there has been that much strife among you because the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Hello I am\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size = NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5338990688323975\n",
      "Eval loss: 6.485144138336182\n"
     ]
    }
   ],
   "source": [
    "#Exercise 5.5- calculating training and validation set losses of the GPTModel with OPenai weights on \"The verdict\" dataset\n",
    "train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter=1)\n",
    "print(\"Train loss:\", train_loss)\n",
    "print(\"Eval loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretation: the verdict text as been use in the gpt training corpus probably "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
