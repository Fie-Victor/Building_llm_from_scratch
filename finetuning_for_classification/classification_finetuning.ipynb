{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IN this section, we are going to finetune a pretrained llm for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use classification finetuning for specified tasks and instruction one for more versatile task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remainder of this chapter, we will modify and classification-finetune the GPT model\n",
    "we implemented and pretrained in the previous chapters. We begin with downloading and\n",
    "preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading and unzippinf the dataset\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\" \n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Download the zip file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "        \n",
    "    \n",
    "    #unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    #adding a .tsv file extantion\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"Data downloaded and extracted to {data_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#class and label distribution\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a balanced dataset with 747 instance of each class for our purpose.\n",
    "NB: there is ways to handle unbalanced data but for simplicity we will create a balanced dataset\n",
    "\n",
    "some unbalanced data handling techniques:\n",
    "- SMOTE (Synthetic Minority Over-sampling Technique): over sampling the minority label \n",
    "- ponderate the label in cross entropie calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_data_set(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]  #A\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123) #B\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]]) #C\n",
    "    return balanced_df\n",
    "balanced_df = create_balanced_data_set(df)\n",
    "print(balanced_df['Label'].value_counts())\n",
    "#A Count the instances of \"spam\"\n",
    "#B Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "#C Combine ham \"subset\" with \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting labels to binary values\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a random_split function to split the dataset into three parts: 70% for\n",
    "training, 10% for validation, and 20% for testing. (These ratios are common in machine\n",
    "learning to train, adjust, and evaluate models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)  #A\n",
    "\n",
    "    train_end = int(len(df) * train_frac) #B\n",
    "    validation_end = train_end + int(len(df) * validation_frac)  #C\n",
    "\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]  \n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "#A Shuffle the entire DataFrame\n",
    "#B Calculate split indices\n",
    "#C Split the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1) #D\n",
    "#D Test size is implied to be 0.2 as the remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can save these datasets to csv files if needed to use later\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating data loaders in pytorch for the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#there is data of diffeerent lenfht (the text message). \n",
    "2 options to create batches:\n",
    " - Truncate all messages to the length of the shortest message in the\n",
    "dataset or batch\n",
    "- Pad all messages to the length of the longest message in the dataset or\n",
    "batch.\n",
    "\n",
    "We opte for the second method to not loss information.\n",
    "we use \"<|endoftext|>\" token as padding token. but we don't add it directly, we w'll add it token id to text token list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating SpamDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "\n",
    "            self.encoded_texts = [  #B Truncate sequences if they are longer than max_length\n",
    "                encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "        \n",
    "        #C Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id]* (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        encoded_text = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded_text, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "#train_dataser\n",
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "print(train_dataset.max_length)\n",
    "#NB: max length should not be more then 1024 as gpt-2 has a limit of 1024 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length, #we use that to ensure that all datasets have the same length\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "num_workers = 0  #A\n",
    "batch_size =8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True, \n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "#A This setting ensures compatibility with most computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "#total size:\n",
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the model for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"model loading\"\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,  #the vocab size of gpt-2\n",
    "    \"context_length\": 1024, #the context length of gpt-2\n",
    "    \"drop_rate\": 0.0, #dropout rate\n",
    "    \"qkv_bias\": True, #add bias to qkv projections\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model context length \"\n",
    "    f\"{BASE_CONFIG['context_length']}. Please choose a model with larger context length\"\n",
    "    f\" or set the dataset max length to `max_length={BASE_CONFIG['context_length']}` when instantiating the dataset.\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../pretraining_on_unlabelled_data/gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: ../pretraining_on_unlabelled_data/gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: ../pretraining_on_unlabelled_data/gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: ../pretraining_on_unlabelled_data/gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../pretraining_on_unlabelled_data/gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: ../pretraining_on_unlabelled_data/gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: ../pretraining_on_unlabelled_data/gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next we use function for last chapter to load the model\n",
    "import sys\n",
    "import pathlib\n",
    "sys.path.append('..')\n",
    "from gpt_download import download_and_load_gpt2\n",
    "from utils import GPTModel, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size = model_size, models_dir=\"../pretraining_on_unlabelled_data/gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you along in a very different direction than it used to, but you are always\n"
     ]
    }
   ],
   "source": [
    "#test of the model\n",
    "from utils import generate , text_to_token_ids, token_ids_to_text\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx = text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    temperature=1.0,\n",
    "    top_k=10,\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the model can do classification before finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    top_k=1\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation for classification-finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#lets see the odel architechture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINETUNING SELECTED LAYERS VERSUS ALL LAYERS\n",
    "\n",
    "Since we start with a pretrained model, it's not necessary to finetune all model\n",
    "layers. This is because, in neural network-based language models, the lower layers\n",
    "generally capture basic language structures and semantics that are applicable across\n",
    "a wide range of tasks and datasets. So, finetuning only the last layers (layers near\n",
    "the output), which are more specific to nuanced linguistic patterns and task-specific\n",
    "features, can often be sufficient to adapt the model to new tasks. A nice side effect is\n",
    "that it is computationally more efficient to finetune only a small number of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the model ready for classification-finetuning, we first freeze the model, meaning that\n",
    "we make all layers non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# all layers are non-trainable (frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we replce the out_pout layer\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)\n",
    "\n",
    "# the new model.out_head output layer has its requires_grad attribute set to True by\n",
    "# default, which means that it's the only layer in the model that will be updated during\n",
    "# training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: finetuning just last layer give good results, but from experiments finetuning additional layers can considerably increase performance. (see Appendix C of the course book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So additionaly we configure the last transformer block and the final LayerNorm module,\n",
    "# which connects this block to the output layer, to be trainable\n",
    "\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "#we can still use the model even if some layers are frozen\n",
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5883,  0.9920],\n",
      "         [-3.7208,  7.4510],\n",
      "         [-2.2642,  6.6005],\n",
      "         [-3.5965,  3.9889]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before a similar input would have produced an output tensor of [1, 4, 50257]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token predictions:\n",
      " tensor([[-3.5965,  3.9889]])\n"
     ]
    }
   ],
   "source": [
    "# to extract the last output token:\n",
    "print(\"Last output token predictions:\\n\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the causal attention mask setup, the last token in a sequence\n",
    "accumulates the most information since it is the only token with access to data from all the\n",
    "previous tokens. Therefore, in our spam classification task, we focus on this last token\n",
    "during the finetuning process.\n",
    "Having modified the model, the next section will detail the process of transforming the\n",
    "last token into class label predictions and calculate the model's initial prediction accuracy.\n",
    "Following this, we will finetune the model for the spam classification task in the subsequent\n",
    "section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: 1\n"
     ]
    }
   ],
   "source": [
    "#obtaining class label of lasst code token\n",
    "probas = torch.softmax(outputs[:,-1,:], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Predicted class label:\", label.item())\n",
    "\n",
    "#predict \"spam\" because not trained yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "# simplification\n",
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy function\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "         num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]        #A\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        return correct_predictions / num_examples\n",
    "#A Extract logits of the last token for classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the function to determine the classification accuracies across various datasets\n",
    "estimated from 10 batches for efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 25.00%\n",
      "Validation accuracy: 50.00%\n",
      "Test accuracy: 62.50%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define a lost function that is differanciable for the training process\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :] # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a loader:\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:                                                               #A\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "#Similar to calculating the training accuracy, we now compute the initial loss for each\n",
    "#data set:\n",
    "with torch.no_grad():                                                       #B\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "#A Ensure number of batches doesn't exceed batches in data loader\n",
    "#B Disable gradient tracking for efficiency because we are not training, yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.200\n",
      "Validation loss: 2.575\n",
      "Test loss: 2.314\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finetuning the model on supervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation function\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetuning the model to classify spam\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device,\n",
    "num_epochs, eval_freq, eval_iter, tokenizer):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() #A\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() #B\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() #C\n",
    "            optimizer.step() #D\n",
    "            examples_seen += input_batch.shape[0] #E\n",
    "            global_step += 1\n",
    "            #F\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        #G\n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "#A Set model to training mode\n",
    "#B Reset loss gradients from previous batch iteration\n",
    "#C Calculate loss gradients\n",
    "#D Update model weights using loss gradients\n",
    "#E New: track examples instead of tokens\n",
    "#F Optional evaluation step\n",
    "#G Calculate accuracy after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ensimag/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.146, Val loss 2.383\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.524, Val loss 0.558\n",
      "Training accuracy: 62.50% | Validation accuracy: 75.00%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.354\n",
      "Training accuracy: 75.00% | Validation accuracy: 87.50%\n",
      "Ep 3 (Step 000300): Train loss 0.334, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.341, Val loss 0.308\n",
      "Training accuracy: 87.50% | Validation accuracy: 100.00%\n",
      "Ep 4 (Step 000400): Train loss 0.144, Val loss 0.210\n",
      "Ep 4 (Step 000450): Train loss 0.157, Val loss 0.136\n",
      "Ep 4 (Step 000500): Train loss 0.224, Val loss 0.139\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.145\n",
      "Ep 5 (Step 000600): Train loss 0.085, Val loss 0.075\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Training completed in: 18.96 minutes\n"
     ]
    }
   ],
   "source": [
    "# \" effective training\"\"\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimiser = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimiser, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_in_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in: {execution_time_in_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the loss function\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    #A\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "    #B\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0) # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "    fig.tight_layout() #C\n",
    "    # plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "#A Plot training and validation loss against epochs\n",
    "#B Create a second x-axis for examples seen\n",
    "#C Adjust layout to make room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the model's training and validation loss over the five training epochs. The training\n",
    "loss, represented by the solid line, and the validation loss, represented by the dashed line, both sharply decline\n",
    "in the first epoch and gradually stabilize towards the fifth epoch. This pattern indicates good learning progress\n",
    "and suggests that the model learned from the training data while generalizing well to the unseen validation\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the number of epochs. There is not rule. If overfitting occurs, reduce the number of epochs\n",
    "#else increase it.\n",
    "#In this case 5 epochs seems resonable as the model learns quickly and does not overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the same plot_values function, let's now also plot the classification accuracies:\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy for all the entire data in each loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 100.00%\n",
      "Validation accuracy: 100.00%\n",
      "Test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our model learn very very greatly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to use the model for prediction\n",
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(text) #A\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)] #B\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids)) #C\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) #D\n",
    "    with torch.no_grad(): #E\n",
    "        logits = model(input_tensor)[:, -1, :] #F\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\" #G\n",
    "\n",
    "#A Prepare inputs to the model\n",
    "#B Truncate sequences if they too long\n",
    "#C Pad sequences to the longest sequence\n",
    "#D Add batch dimension\n",
    "#E Model inference without gradient tracking\n",
    "#F Logits of the last output token\n",
    "#G Return the classified resul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "# \"trying\"\n",
    "text_1 = (\n",
    "\"You are a winner you have been specially\"\n",
    "\" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "# \"another test\"\n",
    "text_2 = (\n",
    "\"Hey, just wanted to check if we're still on\"\n",
    "\" for dinner tonight? Let me know!\"\n",
    ")\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_3 = (\n",
    "\"your account has been compromised. Please send us your password\"\n",
    ")\n",
    "print(classify_review(\n",
    "    text_3, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save it for further use\n",
    "torch.save(model.state_dict(), \"finetuned_gpt2_124M_spam_classifier.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
